{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564dd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # 2. 머신러닝 맛보기1: 분류문제\n",
    "# ## 2-1. 분석 데이터 검토\n",
    "# In[1]:\n",
    "# 분석데이터(유방암) 불러와서 데이터 확인\n",
    "import pandas as pd\n",
    "data=pd.read_csv('breast-cancer-wisconsin.csv', encoding='utf-8')\n",
    "data.head()\n",
    "# In[2]:\n",
    "# 레이블 변수(유방암) 비율 확인\n",
    "data['Class'].value_counts(sort=False)\n",
    "# In[3]:\n",
    "# 행(케이스수)과 열(컬럼수) 구조 확인\n",
    "print(data.shape)\n",
    "\n",
    "# ## 2-2. 특성(X)과 레이블(y) 나누기\n",
    "# In[4]:\n",
    "# 특성과 레이블 데이터 나누기: 특성치 데이터셋을 나누는 방법은 다양함\n",
    "# 방법1: 특성이름으로 특성 데이터셋(X) 나누기\n",
    "X1=data[['Clump_Thickness', 'Cell_Size', 'Cell_Shape', 'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses']]\n",
    "# 방법2: 특성 위치값으로 특성 데이터셋(X) 나누기\n",
    "X2=data[data.columns[1:10]]\n",
    "# 방법3: loc 함수로 특성 데이터셋(X) 나누기 (단, 불러올 특성이 연달아 있어야 함)\n",
    "X3=data.loc[:, 'Clump_Thickness':'Mitoses']\n",
    "# In[5]:\n",
    "# 3가지 방법 모두 동일한 특성치 데이터셋 나눠진 결과 확인\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "print(X3.shape)\n",
    "# In[6]:\n",
    "# 레이블 데이터셋 나누기\n",
    "y=data[[\"Class\"]]\n",
    "# In[7]:\n",
    "# 레이블 데이터셋 행, 열 확인\n",
    "print(y.shape)\n",
    "\n",
    "# ## 2-3. train-test 데이터셋 나누기\n",
    "# In[8]:\n",
    "# 학습용 데이터(train)와 테스트용 데이터(test) 구분을 위한 라이브러리 불러오기\n",
    "# 레이블이 범주형일 경우 straity 옵션 추천\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X1, y, stratify=y, random_state=42)\n",
    "# In[9]:\n",
    "# 학습데이터와 테스트데이터의 0/1 비율이 유사한지 평균으로 확인(stratity 옵션 적용시 유사)\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())\n",
    "\n",
    "# ## 2-4. 정규화\n",
    "# In[10]:\n",
    "# 특성치(X)의 단위 정규화를 위한 라이브러리 블러오기(min-max, standard 2가지 비교)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_minmax=MinMaxScaler()\n",
    "scaler_standard=StandardScaler()\n",
    "# ### 가. train data의 정규화\n",
    "# In[11]:\n",
    "# min-max 방법으로 정규화\n",
    "# 주의!: fit은 학습데이터로 해야, 나중에 test 데이터 정규화시 train 데이터의 최대-최소 기준이 적용됨\n",
    "scaler_minmax.fit(X_train)\n",
    "X_scaled_minmax_train=scaler_minmax.transform(X_train)\n",
    "# In[12]:\n",
    "# standard 방법으로 정규화\n",
    "# 주의!: fit은 학습데이터로 해야, 나중에 test 데이터 정규화시 train 데이터의 표준화(평균, 표준편차) 기준이 적용됨\n",
    "scaler_standard.fit(X_train)\n",
    "X_scaled_standard_train=scaler_standard.transform(X_train)\n",
    "# In[13]:\n",
    "# min-max 방법으로 정규화한 데이터의 기술통계량 확인\n",
    "pd.DataFrame(X_scaled_minmax_train).describe()\n",
    "# In[14]:\n",
    "# standard 방법으로 정규화한 데이터의 기술통계량 확인\n",
    "pd.DataFrame(X_scaled_standard_train).describe()\n",
    "# ### 나. test data의 정규화\n",
    "# In[15]:\n",
    "# test 데이터에도 정규화 적용 및 데이터 확인: min-max 방법\n",
    "X_scaled_minmax_test=scaler_minmax.transform(X_test)\n",
    "pd.DataFrame(X_scaled_minmax_test).describe()\n",
    "# In[16]:\n",
    "# test 데이터에도 정규화 적용 및 데이터 확인: standard 방법\n",
    "X_scaled_standard_test=scaler_standard.transform(X_test)\n",
    "pd.DataFrame(X_scaled_standard_test).describe()\n",
    "\n",
    "# ## 2-5. 모델 학습\n",
    "# In[17]:\n",
    "# ML 알고리즘 모듈 불러오기 및 학습데이터에 적용(LogisticRegression)\n",
    "# 여기서는 min-max 정규화 데이터로 분석\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(X_scaled_minmax_train, y_train)\n",
    "# In[18]:\n",
    "# 분류 예측 결과(0,1)을 'pred_train'에 저장(할당), score로 정확도(accuracy) 확인\n",
    "pred_train=model.predict(X_scaled_minmax_train)\n",
    "model.score(X_scaled_minmax_train, y_train)\n",
    "# In[19]:\n",
    "# 테스트 데이터에 학습데이터의 모델 적용, 'pred_test'에 저장(할당), score로 정확도(accuracy) 확인\n",
    "pred_test=model.predict(X_scaled_minmax_test)\n",
    "model.score(X_scaled_minmax_test, y_test)\n",
    "# In[20]:\n",
    "# 학습데이터의 혼동행렬 보기(정분류, 오분류 교차표)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_train=confusion_matrix(y_train, pred_train)\n",
    "print(\"훈련데이터 오차행렬:\\n\", confusion_train)\n",
    "# In[21]:\n",
    "# 테스트데이터의 혼동행렬 보기(정분류, 오분류 교차표)\n",
    "confusion_test=confusion_matrix(y_test, pred_test)\n",
    "print(\"테스트데이터 오차행렬:\\n\", confusion_test)\n",
    "# In[22]:\n",
    "# 훈련 데이터의 평가지표 상세 확인\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_train=classification_report(y_train, pred_train)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_train)\n",
    "# In[23]:\n",
    "# 테스트 데이터의 평가지표 상세 확인\n",
    "from sklearn.metrics import classification_report\n",
    "cfreport_test=classification_report(y_test, pred_test)\n",
    "print(\"분류예측 레포트:\\n\", cfreport_test)\n",
    "# In[24]:\n",
    "# ROC 지표 산출을 위한 라이브러리 및 산식\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, model.decision_function(X_scaled_minmax_test))\n",
    "roc_auc = metrics.roc_auc_score(y_test, model.decision_function(X_scaled_minmax_test))\n",
    "roc_auc\n",
    "# In[25]:\n",
    "# ROC Curve 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.xlabel('False Positive Rate(1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate(Sensitivity)')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='Model (AUC = %0.2f)'% roc_auc)\n",
    "plt.plot([0,1],[1,1],'y--')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# ## 2-6. 예측값 병합 및 저장\n",
    "# In[26]:\n",
    "# 학습데이터의 예측범주, 예측확률 컬럼을 생성하여 'y_train' 데이터셋에 추가\n",
    "prob_train=model.predict_proba(X_scaled_minmax_train)\n",
    "y_train[['y_pred']]=pred_train\n",
    "y_train[['y_prob0', 'y_prob1']]=prob_train\n",
    "y_train\n",
    "# In[27]:\n",
    "# 테스트 데이터의 예측범주, 예측확률 컬럼을 생성하여 'y_test' 데이터셋에 추가\n",
    "prob_test=model.predict_proba(X_scaled_minmax_test)\n",
    "y_test[['y_pred']]=pred_test\n",
    "y_test[['y_prob0', 'y_prob1']]=prob_test\n",
    "y_test\n",
    "# In[28]:\n",
    "# 테스트 데이터의 특성치(X_test)와 레이블 및 예측치(y_test)를 병합\n",
    "Total_test=pd.concat([X_test, y_test], axis=1)\n",
    "Total_test\n",
    "# In[29]:\n",
    "# csv파일로 내보내기 및 저장\n",
    "Total_test.to_csv(\"classfication_test.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
