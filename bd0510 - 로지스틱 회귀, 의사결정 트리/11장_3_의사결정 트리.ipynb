{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c946607",
   "metadata": {},
   "source": [
    "## DecisionTree-iris-RandomForest\n",
    "- 앙상블 학습: 여러 분류기 생성하고 그 예측 결합해 더 좋은 분류기를 만드는 방법\n",
    "- 앙상블 학습 종류:\n",
    "    1. Voting: 다른 알고리즘 분류기 결합\n",
    "    2. Bagging: 같은 분류기를 중복 샘플링하여 결과 결합(대표적인 게 랜덤 포레스트: 같은 나무 심은 것도 아닌 일정 간격이 있는 것도 아닌 걍 랜덤.. 크기도 갯수도 랜덤)\n",
    "    3. Boosting: 가중치 부여하며 진행...\n",
    "    \n",
    "#### 랜덤 포레스트\n",
    "- 데이터 분류, 데이터 군집, Feature의 중요성 확인, 데이터 예측\n",
    "- 소프트 보팅: 각 분류기의 결정 확률을 집합\n",
    "- 샘플링 시 중복 허용: 같은 데이터 여러 번 뽑을 수 있음\n",
    "- 이론\n",
    "    1. Dataset에서 샘플 데이터 랜덤하게 선택\n",
    "    2. 샘플 데이터에서 feature를 랜덤으로 선택해 의사결정 트리 생성\n",
    "- 예측 모듈\n",
    "    1. Dataset에서 샘플 데이터 선택\n",
    "    2. 샘플 데이터로 의사결정 트리 생성\n",
    "    3. 1, 2 반복\n",
    "    4. 3에서 생성한 n개의 결정 트리 이용해 예측\n",
    "    4. 예측 결과에서 가장 많이 등장하는 결과 선택해 최종 결과로 선택\n",
    "- 특징\n",
    "    1. 여러개 의사결정 결합해서 단인 의사결정 트리 결점 극복\n",
    "    2. 오버 피팅 문제 적음\n",
    "    3. 구현 간단\n",
    "    4. 병렬 계산 간단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11725d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# to excel... by Uchang\n",
    "import pandas as pd \n",
    "df = pd.DataFrame(data=iris['data'], columns = iris['feature_names'])\n",
    "df.to_excel('iris.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e733b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data 설정 \n",
    "x_train = iris.data[:-30]\n",
    "y_train = iris.target[:-30]\n",
    "#test data 설정\n",
    "x_test = iris.data[-30:] # test feature data  \n",
    "y_test = iris.target[-30:] # test target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ca0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier libary를 import\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForest\n",
    "#tree 의 개수 Random Forest 분류 모듈 생성\n",
    "rfc = RandomForestClassifier(n_estimators=10) \n",
    "rfc\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "#Test data를 입력해 target data를 예측 \n",
    "prediction = rfc.predict(x_test)\n",
    "#예측 결과 precision과 실제 test data의 target 을 비교 \n",
    "print (prediction==y_test)\n",
    "#Random forest 정확도 측정\n",
    "rfc.score(x_test, y_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "print (\"Accuracy is : \",accuracy_score(prediction, y_test))\n",
    "print (\"=======================================================\")\n",
    "print (classification_report(prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab364bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2)\n",
    "print (y_test)\n",
    "print (Y_test)\n",
    "clf = RandomForestClassifier(n_estimators=10) # Random Forest\n",
    "clf.fit(X_train, Y_train)\n",
    "prediction_1 = rfc.predict(X_test)\n",
    "#print (prediction_1 == Y_test)\n",
    "print (\"Accuracy is : \",accuracy_score(prediction_1, Y_test))\n",
    "print (\"=======================================================\")\n",
    "print (classification_report(prediction_1, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a32c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "clf_2 = RandomForestClassifier(n_estimators=200, # Number of trees\n",
    "                               max_features=4,    # Num features considered\n",
    "                                  oob_score=True)    # Use OOB scoring*\n",
    "clf_2.fit(X_train, Y_train)\n",
    "prediction_2 = clf_2.predict(X_test)\n",
    "print (prediction_2 == Y_test)\n",
    "print (\"Accuracy is : \",accuracy_score(prediction_2, Y_test))\n",
    "print (\"=======================================================\")\n",
    "print (classification_report(prediction_2, Y_test))\n",
    "\n",
    "for feature, imp in zip(iris.feature_names, clf_2.feature_importances_):\n",
    "    print(feature, imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593553a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import os\n",
    "#os.environ['PATH'] += os.pathsep + 'c:\\programdata\\anaconda3\\lib\\site-packages'\n",
    "estimator = clf_2.estimators_[5]\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = iris.feature_names,\n",
    "                class_names = iris.target_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# 생성된 .dot 파일을 .png로 변환\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'decistion-tree.png', '-Gdpi=50'])\n",
    "\n",
    "# jupyter notebook에서 .png 직접 출력\n",
    "from IPython.display import Image\n",
    "\n",
    "# 다음 명령어는 따로 실행해본다.\n",
    "Image(filename = 'decistion-tree.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
